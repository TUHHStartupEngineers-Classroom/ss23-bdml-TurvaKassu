
### Downloading libraries and data
```{r}
library(tidyverse)
library(h2o)
library(skimr)
library(rsample)
library(recipes)
library(cowplot)
library(glue)
library(dbplyr)
library(tidyr)

h2o.init()
```

Reading data
```{r}
backorder_tbl <- read.csv("08_data\\product_backorder.csv")
```


### Getting to know data

```{r}
skim(backorder_tbl)
```

lead_time only column to have missing values (6%), lets fill them with
average of the lead_time column
```{r}
backorder_tbl <- backorder_tbl %>%
  mutate(lead_time = ifelse(is.na(lead_time), mean(lead_time, na.rm = TRUE), 
                            lead_time)) %>%
  mutate_if(is.character, as.factor)
```




### Processing data for h20
```{r}
# H2O modeling



set.seed(seed = 1113)
split_obj                       <- rsample::initial_split(backorder_tbl, prop = 0.85)
train_readable_tbl              <- training(split_obj)
test_readable_tbl               <- testing(split_obj)

recipe_obj <- recipe(went_on_backorder ~., data = train_readable_tbl) %>% 
    update_role(sku, new_role = "id") %>%
    step_zv(all_predictors()) %>% 
    prep()

train_tbl <- bake(recipe_obj, new_data = train_readable_tbl)
test_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)
```



### Running the h20 analysis
```{r}
# Modeling
h2o.init()

# Split data into a training and a validation data frame
split_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)
train_h2o <- split_h2o[[1]]
valid_h2o <- split_h2o[[2]]
test_h2o  <- as.h2o(test_tbl)

# Set the target and predictors
y <- "went_on_backorder"
x <- setdiff(names(train_h2o), y)

# Creating the models
automl_models_h2o <- h2o.automl(
  x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 45,
  nfolds            = 10 
)
```

### Viewing the results on leaderboard

```{r}
# Best models
automl_models_h2o@leaderboard

# Saving the id of best model
best_model_id <- automl_models_h2o@leaderboard %>%
  as_tibble() %>%
  slice(1) %>% 
  pull(model_id)
```

### Pulling the best model & Saving

```{r}
h2o.getModel(best_model_id) %>%
  h2o.saveModel(path = "08_data\\models")
```


# Challenge Performance measurements

### Visualizing the leaderboard

Wrangling data
```{r}
data_transformed_tbl <- automl_models_h2o@leaderboard %>%
        as_tibble() %>%
        select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% 
        mutate(model_type = str_extract(model_id, "[^_]+")) %>%
        slice(1:15) %>% 
        rownames_to_column(var = "rowname") %>%
        
        # Reordering factors
        mutate(
          model_id   = as_factor(model_id) %>% reorder(auc),
          model_type = as_factor(model_type)
          ) %>% 
          pivot_longer(cols = -c(model_id, model_type, rowname), 
                       names_to = "key", 
                       values_to = "value", 
                       names_transform = list(key = forcats::fct_inorder)
                       ) %>% 
        mutate(model_id = paste0(rowname, ". ", model_id) %>% as_factor() %>% fct_rev())

```


Plotting leaderboard

```{r}
data_transformed_tbl %>%
        ggplot(aes(value, model_id, color = model_type)) +
        geom_point(size = 3) +
        geom_label(aes(label = round(value, 2), hjust = "inward")) +
        
        # Facet to break out logloss and auc
        facet_wrap(~ key, scales = "free_x") +
        labs(title = "Leaderboard Metrics",
             subtitle = paste0("Ordered by: ", "auc"),
             y = "Model Postion, Model ID", x = "") + 
        theme(legend.position = "bottom")
```

Lets tune the GBM model that scored the third best score

### Tuning the Stacked Ensemble model with grid search


```{r}
hyper_params <- list(
  ntrees = c(50, 100, 150),
  max_depth = c(3, 5, 7),
  learn_rate = c(0.1, 0.01, 0.001)
)

# Create the grid of GBM models
grid <- h2o.grid(
  algorithm = "gbm",
  grid_id = "gbm_grid",
  hyper_params = hyper_params,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  y = "went_on_backorder"
)
```
Let's test the model
```{r}
grid

h2o.getGrid(grid_id = "gbm_grid", sort_by = "auc", decreasing = TRUE)
```

It seems that the logloss of the best model was few fractions better, but
the auc was equally worse. Let's use the Stacked Ensemble model in the 
future visualisazions.


### Finding the optimal threshold 

```{r}
performance_h2o <- h2o.performance(h2o.getModel(best_model_id), newdata = as.h2o(test_tbl))

performance_tbl <- performance_h2o %>%
    h2o.metric() %>%
    as_tibble()
```




Lets set a custom theme

```{r}
theme_new <- theme(
      legend.position  = "bottom",
      legend.key       = element_blank(),
      panel.background = element_rect(fill   = "transparent"),
      panel.border     = element_rect(color = "black", fill = NA),
      panel.grid.major = element_line(color = "grey", linewidth = 0.333)
      ) 
```


Plotting the optimal threshold with best F1-score

```{r}
performance_tbl %>%
    filter(f1 == max(f1))

performance_tbl %>%
    ggplot(aes(x = threshold)) +
    geom_line(aes(y = precision), color = "blue", size = 1) +
    geom_line(aes(y = recall), color = "red", size = 1) +
    
    # Insert line where precision and recall are harmonically optimized
    geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, "f1")) +
    labs(title = "Precision vs Recall", y = "value") +
    theme_new
```


### ROC Plot

```{r}
h2o.init()

# Plot the ROC curve
roc_p <- plot(performance_h2o, type = "roc", main = 'roc')
```

### Precission VS Recall

```{r}
# Plot the Precision-Recall curve
pr_p <- plot(performance_h2o, type = "pr", main = "Precision-Recall Curve", xlab = "Recall", ylab = "Precision")
```

### Gain & Lift plots

```{r}
gain_lift_tbl <- performance_h2o %>%
    h2o.gainsLift() %>%
    as.tibble()

## Gain Chart

gain_transformed_tbl <- gain_lift_tbl %>% 
    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%
    select(-contains("lift")) %>%
    mutate(baseline = cumulative_data_fraction) %>%
    rename(gain     = cumulative_capture_rate) %>%
    # prepare the data for the plotting (for the color and group aesthetics)
    pivot_longer(cols = c(gain, baseline), values_to = "value", names_to = "key")

gain_p <- gain_transformed_tbl %>%
    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +
    geom_line(size = 1.5) +
    labs(
        title = "Gain Chart",
        x = "Cumulative Data Fraction",
        y = "Gain"
    ) +
    theme_new

gain_p


## Lift Chart
lift_transformed_tbl <- gain_lift_tbl %>% 
    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%
    select(-contains("capture")) %>%
    mutate(baseline = 1) %>%
    rename(lift = cumulative_lift) %>%
    pivot_longer(cols = c(lift, baseline), values_to = "value", names_to = "key")

lift_p <- lift_transformed_tbl %>%
    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +
    geom_line(size = 1.5) +
    labs(
        title = "Lift Chart",
        x = "Cumulative Data Fraction",
        y = "Lift"
    ) +
    theme_new

lift_p
```

### Dashboard with cowplot

```{r}
# Combine plots
p <- cowplot::plot_grid(roc_p, pr_p, gain_p,  lift_p, ncol = 2)

# Title
p_title <- ggdraw() + 
        draw_label("H2O Model Metrics", size = 18, fontface = "bold", 
                   color = "#2C3E50")

# Combine everything
ret <- plot_grid(p_title,  p,
                 ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * 4))

ret
```








